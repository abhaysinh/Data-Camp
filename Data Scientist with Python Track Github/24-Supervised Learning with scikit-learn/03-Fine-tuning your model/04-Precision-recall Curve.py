
'''

Precision-recall Curve

When looking at your ROC curve, you may have noticed that the y-axis (True positive rate) is also known as recall.
Indeed, in addition to the ROC curve, there are other ways to visually evaluate model performance.
One such way is the precision-recall curve, which is generated by plotting the precision and recall for different thresholds.
As a reminder, precision and recall are defined as:

Precision=TP / TP+FP

Recall=TP / TP+FN

On the right, a precision-recall curve has been generated for the diabetes dataset.
The classification report and confusion matrix are displayed in the IPython Shell.

Study the precision-recall curve and then consider the statements given below. Choose the one statement that is not true.
Note that here, the class is positive (1) if the individual has diabetes.

Instructions
50 XP

Possible Answers

    -A recall of 1 corresponds to a classifier with a low threshold in which all females who contract diabetes were
    correctly classified as such, at the expense of many misclassifications of those who did not have diabetes.

    -Precision is undefined for a classifier which makes no positive predictions, that is, classifies everyone as not
    having diabetes.

    -When the threshold is very close to 1, precision is also 1, because the classifier is absolutely certain about
    its predictions.

    -Precision and recall take true negatives into consideration.

Answer : Precision and recall take true negatives into consideration.

'''